---
title: Configuration
description: CowAgent configuration file reference
---

# Configuration

The config template is located at `config-template.json` in the project root. Copy it to create the active `config.json`:

```bash
cp config-template.json config.json
```

## Core Settings

```json
{
  "channel_type": "web",
  "model": "MiniMax-M2.5",
  "agent": true,
  "agent_workspace": "~/cow",
  "agent_max_context_tokens": 40000,
  "agent_max_context_turns": 30,
  "agent_max_steps": 15
}
```

| Parameter | Description | Default |
| --- | --- | --- |
| `channel_type` | Channel type | `web` |
| `model` | Model name | `MiniMax-M2.5` |
| `agent` | Enable Agent mode | `true` |
| `agent_workspace` | Agent workspace path | `~/cow` |
| `agent_max_context_tokens` | Maximum context tokens | `40000` |
| `agent_max_context_turns` | Maximum context conversation turns | `30` |
| `agent_max_steps` | Maximum tool call steps per task | `15` |

## Model API Keys

Fill in the API key for your chosen model:

```json
{
  "minimax_api_key": "",
  "zhipu_ai_api_key": "",
  "moonshot_api_key": "",
  "ark_api_key": "",
  "dashscope_api_key": "",
  "claude_api_key": "",
  "gemini_api_key": "",
  "open_ai_api_key": ""
}
```

See [Models](/en/models) for detailed model configuration.

## Voice Settings

```json
{
  "speech_recognition": false,
  "group_speech_recognition": false,
  "voice_reply_voice": false
}
```

| Parameter | Description |
| --- | --- |
| `speech_recognition` | Enable private chat voice recognition |
| `group_speech_recognition` | Enable group chat voice recognition |
| `voice_reply_voice` | Reply to voice messages with voice |

## LinkAI Settings

```json
{
  "use_linkai": false,
  "linkai_api_key": "",
  "linkai_app_code": ""
}
```

| Parameter | Description |
| --- | --- |
| `use_linkai` | Enable LinkAI integration |
| `linkai_api_key` | LinkAI API Key, create at [console](https://link-ai.tech/console/interface) |
| `linkai_app_code` | LinkAI app or workflow code |

## Proxy Settings

If you need a network proxy:

```json
{
  "proxy": "127.0.0.1:7890"
}
```

<Tip>
  For all configuration options, see the [`config.py`](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/config.py) file in the project.
</Tip>
